# Simple chain

Example of a simple workflow that consists of a

* preprocessing step,
* a processing step that requires multiple cores, and
* a postprocessing step.


## What is it?

1. `preprocess.py`: Python script for the preprocessing step.  It generates a
   file with a given number of 2D-points.
1. `process.py`: Python script for the processing step.  It reads the file
   generated by the preprocessing step, and computes the distance between all
   pairs of points.  It uses multiple cores to do so.
1. `postprocess.py`: Python script for the postprocessing step.  It reads the
   file generated by the processing step, and computes the distribution of the
   distances.
1. `workflow.nf`: Nextflow script defining the workflow.
1. `nextflow.config`: Nextflow configuration file that defines three profiles,
   a `standard` one that only enables conda, a `laptop` profile that uses
   multiple cores, and a `cluster` profile that uses the `slurm` executor.
1. `conda_environment.yml`: conda environment file to create the environment
   required by the `Process` step of the workflow.
1. `conda_init.sh`: Bash script to initialize the shell for conda use.
   **Note:** this script is only sourced when running the workflow with the
   `slurm` executor, i.e., with configuration file `nextflow_slurm.config`.
1. `nextflow_small.config`: Nextflow configuration file to illustrate that
   parameters can be overridden via the command line.


## How to use it?

To run the workflow locally,
```bash
$ nextflow run workflow.nf -profile laptop
```

To run the workflow on a Slurm cluster,
```bash
$ nextflow run workflow.nf -profile cluster
```
